{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56c5b381-2cb2-4701-a84d-63ff0cac11fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<span style=\"color:orange\">\n",
    " <h2> Databircks-Assignemnt 4: Advance String Manupulation Transformation)\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5625faf-7cad-432c-92a2-75e00388d984",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ac1d97b-2ffa-4cb8-a030-ef9165803c51",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de97f6e0-41cc-42c9-9845-7dc34319ba49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- first_name: string (nullable = true)\n |-- last_name: string (nullable = true)\n |-- email: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n |-- creationDate: timestamp (nullable = true)\n |-- bonus: double (nullable = true)\n\n+---+----------+---------+--------------------+------+------+-------------------+--------+\n| id|first_name|last_name|               email|gender|salary|       creationDate|   bonus|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\n|  1|    Valene|   Ingley|vingley0@livejour...|Female| 44104|1957-09-09 16:44:40|    null|\n|  2|  Lynnelle|    Hurll| lhurll1@answers.com|Female|112411|1907-05-10 17:38:56|    null|\n|  3|   Miranda|    Train|   mtrain2@imgur.com|Female| 91073|1941-01-24 16:05:23|12875.54|\n|  4|    Dulsea|     Foss|dfoss3@dagondesig...|Female|193291|1942-05-09 20:59:39|    null|\n|  5|    Anatol|  Dunklee| adunklee4@google.de|  Male| 22175|1950-07-26 16:28:00| 1432.12|\n|  6|     Baily|   Antony| bantony5@sfgate.com|  Male|127337|1913-10-14 11:25:33|    null|\n|  7|    Eunice|   Cardus|ecardus6@scientif...|Female|136574|1901-11-02 15:09:47|38676.94|\n|  8|  Aubrette|  Lippett| alippett7@nifty.com|Female|165713|1919-12-16 08:20:42|60150.66|\n|  9|   Sibylla|Sickamore|ssickamore8@faceb...|Female|107243|2020-03-15 15:00:30|    null|\n| 10|      null|   Altree|paltree9@dropbox.com|Female|197594|1975-06-21 23:27:12|72533.37|\n| 11|      Coop|    Richt|   crichta@sogou.com|  Male| 19964|1939-02-13 16:18:24|56973.41|\n| 12|  Giuseppe|  Scimoni|gscimonib@craigsl...|  Male|176531|1967-04-06 07:23:03|    null|\n| 13|    Lovell|  Iorizzo|liorizzoc@cpanel.net|  Male|189150|1949-06-06 16:25:20| 41474.8|\n| 14|       Deb|    Mogra|   dmograd@bbc.co.uk|Female|197829|1997-07-27 14:55:52|46528.57|\n| 15|  Hastings| Jelliman|hjellimane@histat...|  Male|179296|1915-07-05 07:02:06|80194.64|\n| 16|     Josee|   Burnep|    jburnepf@php.net|  null| 78569|1923-11-08 20:59:14|88925.13|\n| 17|     Gilly|   Fownes|gfownesg@redcross...|Female|  2527|1946-07-30 21:10:57|    null|\n| 18|      null|Schruyers|lschruyersh@desde...|  Male|109936|1979-06-16 01:12:48|37243.09|\n| 19|     Maris|Chatelain| mchatelaini@unc.edu|Female|190047|2008-01-11 17:16:21|76469.65|\n| 20|    Casper|  Aughtie|    caughtiej@vk.com|  Male| 38689|1982-04-06 05:13:49| 80404.8|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"dbfs:/FileStore/shared_uploads/aakashpavale8877@gmail.com/EmployeeData_HhTLiz9LdC_2JpHdxGvrY-1.csv\", header=True, inferSchema=True, sep =',')\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01541cf5-29d4-4dbe-a0a2-9666393c4171",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<b> What is the abbreviated version of each employee's last name, with the first letter and the two following letters included?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83f0e040-3b07-4e4d-842b-6eedba9aa448",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n|abr last name|\n+-------------+\n|          Ing|\n|          Hur|\n|          Tra|\n|          Fos|\n|          Dun|\n|          Ant|\n|          Car|\n|          Lip|\n|          Sic|\n|          Alt|\n|          Ric|\n|          Sci|\n|          Ior|\n|          Mog|\n|          Jel|\n|          Bur|\n|          Fow|\n|          Sch|\n|          Cha|\n|          Aug|\n+-------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "abr_last_name = df.select(col(\"last_name\").substr(1,3).alias('abr last name'))\n",
    "abr_last_name.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7596956d-789a-43c8-b3e7-470db0f35fca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "<b> What is the domain name of each employee's email address, so that their emails can be filtered and routed to the correct department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2bc2ab9-4479-4ed0-a510-b0ec1455a9a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n|        email_domain|\n+--------------------+\n|     livejournal.com|\n|         answers.com|\n|           imgur.com|\n|     dagondesign.com|\n|           google.de|\n|          sfgate.com|\n|scientificamerica...|\n|           nifty.com|\n|        facebook.com|\n|         dropbox.com|\n|           sogou.com|\n|      craigslist.org|\n|          cpanel.net|\n|           bbc.co.uk|\n|         histats.com|\n|             php.net|\n|        redcross.org|\n|           desdev.cn|\n|             unc.edu|\n|              vk.com|\n+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "email_domain = df.select(split(col(\"email\"),'@').getItem(1).alias(\"email_domain\"))\n",
    "email_domain.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdb6949e-fbda-47a0-b9e3-9b5aa8e5788b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "<b> In an effort to protect their privacy, what is each employee's name spelled backwards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8172873-7db2-4382-850c-569ba2491ad2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n|        rev_name|\n+----------------+\n|    yelgnIenelaV|\n|   llruHellennyL|\n|    niarTadnariM|\n|      ssoFaesluD|\n|   eelknuDlotanA|\n|     ynotnAyliaB|\n|    sudraCecinuE|\n| tteppiLetterbuA|\n|eromakciSallybiS|\n|            null|\n|       thciRpooC|\n| inomicSeppesuiG|\n|   ozziroIllevoL|\n|        argoMbeD|\n|namilleJsgnitsaH|\n|     penruBeesoJ|\n|     senwoFylliG|\n|            null|\n|  nialetahCsiraM|\n|   eithguArepsaC|\n+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "rev_first_name = df.select(reverse((concat(col(\"first_name\"),col(\"last_name\")))).alias('rev_name'))\n",
    "rev_first_name.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a7155e5-4aa6-4e30-b244-fc6ad8d3fed8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "<b> In order to make their email addresses harder to guess, what is each employee's email address spelled backwards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b10ce1ed-e48d-493d-8148-63acadce18e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n|reverse(email AS rev_email)|\n+---------------------------+\n|       moc.lanruojevil@0...|\n|        moc.srewsna@1llruhl|\n|          moc.rugmi@2niartm|\n|       moc.ngisednogad@3...|\n|        ed.elgoog@4eelknuda|\n|        moc.etagfs@5ynotnab|\n|       moc.naciremacifit...|\n|        moc.ytfin@7tteppila|\n|       moc.koobecaf@8ero...|\n|       moc.xobpord@9eertlap|\n|          moc.uogos@athcirc|\n|       gro.tsilsgiarc@bi...|\n|       ten.lenapc@cozziroil|\n|          ku.oc.cbb@dargomd|\n|       moc.statsih@enami...|\n|           ten.php@fpenrubj|\n|       gro.ssorcder@gsen...|\n|       nc.vedsed@hsreyur...|\n|        ude.cnu@inialetahcm|\n|           moc.kv@jeithguac|\n+---------------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "rev_email = df.select(reverse((col(\"email\")).alias('rev_email')))\n",
    "rev_email.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15178c86-7b61-4b25-a42e-850363b01dd6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "<b> What is each employee's first name, repeated twice, to improve personalization of emails and messages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8fd7215-3afd-4fd9-9c43-51ca81c25aa2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n|concat(first_name,  , first_name)|\n+---------------------------------+\n|                    Valene Valene|\n|                Lynnelle Lynnelle|\n|                  Miranda Miranda|\n|                    Dulsea Dulsea|\n|                    Anatol Anatol|\n+---------------------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "rep_first_name = df.select(concat(col(\"first_name\"),lit(\" \"),col(\"first_name\")))\n",
    "rep_first_name.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca3eba0e-0df9-42b8-bc99-39867c2a7e82",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "<b> What is the country code of each employee's email domain, which can help identify global market opportunities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b3a65e9-58dc-43a4-b926-31bae3f440b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n|country_code|\n+------------+\n|         com|\n|         com|\n|         com|\n|         com|\n|          de|\n|         com|\n|         com|\n|         com|\n|         com|\n|         com|\n|         com|\n|         org|\n|         net|\n|          uk|\n|         com|\n|         net|\n|         org|\n|          cn|\n|         edu|\n|         com|\n+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "country_code_email = df.select(substring_index(col(\"email\"),'.',-1).alias('country_code'))\n",
    "country_code_email.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6db5e71a-f747-43fc-8834-1c348a80a44b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "<b> What is the position of the first occurrence of a dot ('.') character in each employee's email address, which can be used to standardize email addresses in a database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f13f23e-65f5-443a-86cf-b28f16fa7389",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n|dot_pos|\n+-------+\n|     21|\n|     16|\n|     14|\n|     19|\n|     17|\n|     16|\n|     28|\n|     16|\n|     21|\n|     17|\n|     14|\n|     21|\n|     17|\n|     12|\n|     19|\n|     13|\n|     18|\n|     19|\n|     16|\n|     13|\n+-------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark \n",
    "dot_pos = df.select(instr(col(\"email\"),\".\").alias('dot_pos'))\n",
    "dot_pos.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85b1a79d-65b9-4a95-831a-57eea6c251f9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "<b> What is the full name and email address of each employee, concatenated with a space separator, for use in email communication?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4708e08e-0200-4e40-a9ed-87f0a3e72bc6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n|details                                      |\n+---------------------------------------------+\n|Valene Ingley vingley0@livejournal.com       |\n|Lynnelle Hurll lhurll1@answers.com           |\n|Miranda Train mtrain2@imgur.com              |\n|Dulsea Foss dfoss3@dagondesign.com           |\n|Anatol Dunklee adunklee4@google.de           |\n|Baily Antony bantony5@sfgate.com             |\n|Eunice Cardus ecardus6@scientificamerican.com|\n|Aubrette Lippett alippett7@nifty.com         |\n|Sibylla Sickamore ssickamore8@facebook.com   |\n|Altree paltree9@dropbox.com                  |\n|Coop Richt crichta@sogou.com                 |\n|Giuseppe Scimoni gscimonib@craigslist.org    |\n|Lovell Iorizzo liorizzoc@cpanel.net          |\n|Deb Mogra dmograd@bbc.co.uk                  |\n|Hastings Jelliman hjellimane@histats.com     |\n|Josee Burnep jburnepf@php.net                |\n|Gilly Fownes gfownesg@redcross.org           |\n|Schruyers lschruyersh@desdev.cn              |\n|Maris Chatelain mchatelaini@unc.edu          |\n|Casper Aughtie caughtiej@vk.com              |\n+---------------------------------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "full_name = df.select(concat_ws(' ',col(\"first_name\"),col(\"last_name\"),col(\"email\")).alias(\"details\"))\n",
    "full_name.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34faa5af-6a42-4638-860e-0a8248284e63",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "<b> What is the first letter of each employee's first name in uppercase, followed by the rest of the name in lowercase, to ensure consistency and proper capitalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfb43dc0-bb19-4109-bbb4-090859ce1363",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|First Name|\n+----------+\n|    Valene|\n|  Lynnelle|\n|   Miranda|\n|    Dulsea|\n|    Anatol|\n|     Baily|\n|    Eunice|\n|  Aubrette|\n|   Sibylla|\n|      null|\n|      Coop|\n|  Giuseppe|\n|    Lovell|\n|       Deb|\n|  Hastings|\n|     Josee|\n|     Gilly|\n|      null|\n|     Maris|\n|    Casper|\n+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "init_first_name = df.select(initcap(col(\"first_name\")).alias(\"First Name\"))\n",
    "init_first_name.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Databircks-Assignemnt4- Aakash Pavale Advance String Manupulation Transformation)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
