{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df7e83ba-34cd-4f9e-8fb5-eb5ec719cf28",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<span style=\"color:orange\">\n",
    " <h2> Databricks-Assignemnt 2 (Basic Data Cleaning Transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41111864-8465-46e2-800b-abb12e91918b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05366a3a-558c-4478-9f37-e670b7d7da0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- first_name: string (nullable = true)\n |-- last_name: string (nullable = true)\n |-- email: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n |-- creationDate: timestamp (nullable = true)\n |-- bonus: double (nullable = true)\n\n+---+----------+---------+--------------------+------+------+-------------------+--------+\n| id|first_name|last_name|               email|gender|salary|       creationDate|   bonus|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\n|  1|    Valene|   Ingley|vingley0@livejour...|Female| 44104|1957-09-09 16:44:40|    null|\n|  2|  Lynnelle|    Hurll| lhurll1@answers.com|Female|112411|1907-05-10 17:38:56|    null|\n|  3|   Miranda|    Train|   mtrain2@imgur.com|Female| 91073|1941-01-24 16:05:23|12875.54|\n|  4|    Dulsea|     Foss|dfoss3@dagondesig...|Female|193291|1942-05-09 20:59:39|    null|\n|  5|    Anatol|  Dunklee| adunklee4@google.de|  Male| 22175|1950-07-26 16:28:00| 1432.12|\n|  6|     Baily|   Antony| bantony5@sfgate.com|  Male|127337|1913-10-14 11:25:33|    null|\n|  7|    Eunice|   Cardus|ecardus6@scientif...|Female|136574|1901-11-02 15:09:47|38676.94|\n|  8|  Aubrette|  Lippett| alippett7@nifty.com|Female|165713|1919-12-16 08:20:42|60150.66|\n|  9|   Sibylla|Sickamore|ssickamore8@faceb...|Female|107243|2020-03-15 15:00:30|    null|\n| 10|      null|   Altree|paltree9@dropbox.com|Female|197594|1975-06-21 23:27:12|72533.37|\n| 11|      Coop|    Richt|   crichta@sogou.com|  Male| 19964|1939-02-13 16:18:24|56973.41|\n| 12|  Giuseppe|  Scimoni|gscimonib@craigsl...|  Male|176531|1967-04-06 07:23:03|    null|\n| 13|    Lovell|  Iorizzo|liorizzoc@cpanel.net|  Male|189150|1949-06-06 16:25:20| 41474.8|\n| 14|       Deb|    Mogra|   dmograd@bbc.co.uk|Female|197829|1997-07-27 14:55:52|46528.57|\n| 15|  Hastings| Jelliman|hjellimane@histat...|  Male|179296|1915-07-05 07:02:06|80194.64|\n| 16|     Josee|   Burnep|    jburnepf@php.net|  null| 78569|1923-11-08 20:59:14|88925.13|\n| 17|     Gilly|   Fownes|gfownesg@redcross...|Female|  2527|1946-07-30 21:10:57|    null|\n| 18|      null|Schruyers|lschruyersh@desde...|  Male|109936|1979-06-16 01:12:48|37243.09|\n| 19|     Maris|Chatelain| mchatelaini@unc.edu|Female|190047|2008-01-11 17:16:21|76469.65|\n| 20|    Casper|  Aughtie|    caughtiej@vk.com|  Male| 38689|1982-04-06 05:13:49| 80404.8|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"dbfs:/FileStore/shared_uploads/aakashpavale8877@gmail.com/EmployeeData_HhTLiz9LdC_2JpHdxGvrY-1.csv\",header=True, inferSchema=True, sep =',')\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62c53c84-5d19-4115-a775-314575ce42fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<b> Find the count of duplicate employee records in the input file (based on id)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d4e6162-dd1d-497a-b403-121b7b3ad8da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n|first_name|last_name|\n+----------+---------+\n|   Giacomo|     null|\n+----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "#did not find any duplicated as per id so did it on first name and lasst name basis\n",
    "dup_count = df.groupBy('first_name','last_name').agg(count('id').alias('countofids')).orderBy(desc_nulls_last('countofids'))\n",
    "result = dup_count.filter(dup_count.countofids > 1).select('first_name','last_name')\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8364e840-c519-4ac5-a1bf-b9b89b994321",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<b> Find out how many records have Gender value missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0185598-138a-4fd1-a503-3e1a0c301712",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n|Countofidswithgenderasnull|\n+--------------------------+\n|                        28|\n+--------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "gender_missing = df.where(df.gender.isNull()).select(count('id').alias(\"Countofidswithgenderasnull\"))\n",
    "gender_missing.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14772c70-beff-49d9-828a-724188863639",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "<b> Are there any missing values in the \"bonus\" field? If so, filled them defualt bonus 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5233f351-ed0d-4c5d-8c49-b382053a6e91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------+------+-------------------+--------+\n| id|first_name|last_name|               email|gender|salary|       creationDate|   bonus|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\n|  1|    Valene|   Ingley|vingley0@livejour...|Female| 44104|1957-09-09 16:44:40|   100.0|\n|  2|  Lynnelle|    Hurll| lhurll1@answers.com|Female|112411|1907-05-10 17:38:56|   100.0|\n|  3|   Miranda|    Train|   mtrain2@imgur.com|Female| 91073|1941-01-24 16:05:23|12875.54|\n|  4|    Dulsea|     Foss|dfoss3@dagondesig...|Female|193291|1942-05-09 20:59:39|   100.0|\n|  5|    Anatol|  Dunklee| adunklee4@google.de|  Male| 22175|1950-07-26 16:28:00| 1432.12|\n|  6|     Baily|   Antony| bantony5@sfgate.com|  Male|127337|1913-10-14 11:25:33|   100.0|\n|  7|    Eunice|   Cardus|ecardus6@scientif...|Female|136574|1901-11-02 15:09:47|38676.94|\n|  8|  Aubrette|  Lippett| alippett7@nifty.com|Female|165713|1919-12-16 08:20:42|60150.66|\n|  9|   Sibylla|Sickamore|ssickamore8@faceb...|Female|107243|2020-03-15 15:00:30|   100.0|\n| 10|      null|   Altree|paltree9@dropbox.com|Female|197594|1975-06-21 23:27:12|72533.37|\n| 11|      Coop|    Richt|   crichta@sogou.com|  Male| 19964|1939-02-13 16:18:24|56973.41|\n| 12|  Giuseppe|  Scimoni|gscimonib@craigsl...|  Male|176531|1967-04-06 07:23:03|   100.0|\n| 13|    Lovell|  Iorizzo|liorizzoc@cpanel.net|  Male|189150|1949-06-06 16:25:20| 41474.8|\n| 14|       Deb|    Mogra|   dmograd@bbc.co.uk|Female|197829|1997-07-27 14:55:52|46528.57|\n| 15|  Hastings| Jelliman|hjellimane@histat...|  Male|179296|1915-07-05 07:02:06|80194.64|\n| 16|     Josee|   Burnep|    jburnepf@php.net|  null| 78569|1923-11-08 20:59:14|88925.13|\n| 17|     Gilly|   Fownes|gfownesg@redcross...|Female|  2527|1946-07-30 21:10:57|   100.0|\n| 18|      null|Schruyers|lschruyersh@desde...|  Male|109936|1979-06-16 01:12:48|37243.09|\n| 19|     Maris|Chatelain| mchatelaini@unc.edu|Female|190047|2008-01-11 17:16:21|76469.65|\n| 20|    Casper|  Aughtie|    caughtiej@vk.com|  Male| 38689|1982-04-06 05:13:49| 80404.8|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "fill_cols_vals = {\"bonus\": 100}\n",
    "df1 = df.na.fill(fill_cols_vals)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cae0fe03-6339-4dac-9a18-1a5a1da78612",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "<b> Are there any employees with negative salary or bonus amounts in the input file? If so, how many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bf0728d-c9ff-4d5f-9cb4-00d7a34bb988",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+-----+\n| id|first_name|last_name|salary|bonus|\n+---+----------+---------+------+-----+\n+---+----------+---------+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "negative_values = df.where(\"salary < 0 or bonus < 0\").select('id','first_name','last_name','salary','bonus')\n",
    "negative_values.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e58642b-6aff-4351-92a0-cea48bfdc948",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "<b> Replace all the null/emtpy value in email column with admin@azurelib.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4288320d-f41e-4719-99a6-93fe790beacb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----------+------------------+------+------+-------------------+--------+\n|  id|first_name|  last_name|             email|gender|salary|       creationDate|   bonus|\n+----+----------+-----------+------------------+------+------+-------------------+--------+\n|  21|    Kristo|    Giraudy|admin@azurelib.com|  Male|152116|1962-08-16 21:27:30| 5982.54|\n|  28| Sallyanne|  Iacobucci|admin@azurelib.com|Female|  2339|1939-05-10 11:30:31| 66003.0|\n|  29|      null|     Nibley|admin@azurelib.com|Female|165764|2019-08-30 11:23:27|93953.74|\n|  46|Kristoforo|     Sowray|admin@azurelib.com|  Male|131676|1959-03-14 16:01:23|27022.26|\n|  64|   Cordell|Baszkiewicz|admin@azurelib.com|  Male| 89429|1998-04-26 03:44:59|50640.06|\n|  67|    Aloise|   Brombell|admin@azurelib.com|Female| 51529|1987-02-16 16:02:18|    null|\n|  70|    Lianne|       Boam|admin@azurelib.com|Female| 13695|1981-04-08 20:31:44|    null|\n|  78|   Jillian|    Chasmar|admin@azurelib.com|Female| 18805|2019-01-07 02:06:41|93412.65|\n|  95|     Davey|  Woodworth|admin@azurelib.com|  Male|  8569|2000-05-24 18:03:02|92849.24|\n|  97|    Thorpe|    Gabotti|admin@azurelib.com|  Male|167464|1982-06-30 21:33:46|  8679.7|\n|null|    Darren|       null|admin@azurelib.com|  Male|111848|1940-11-30 02:35:02| 6461.19|\n| 116|      null|      Jados|admin@azurelib.com|  Male| 56578|2002-05-29 06:33:36|    null|\n| 123|    Malchy|  Whitefoot|admin@azurelib.com|  Male| 28052|1918-08-05 15:45:12|39117.02|\n| 142|       Erv|     Griggs|admin@azurelib.com|  Male|144655|2007-11-09 22:05:38| 95251.8|\n| 145|     Adele|     Taylot|admin@azurelib.com|Female|  null|1968-01-14 05:31:32|    null|\n| 146|    Amargo|   Tresvina|admin@azurelib.com|Female|185482|1962-04-26 20:02:19|45135.71|\n| 152|    Lorrin|   Stopford|admin@azurelib.com|Female| 53416|1918-07-11 08:09:31|94705.56|\n| 163|   Jeffrey|     Sugars|admin@azurelib.com|  Male|112937|1978-08-15 19:03:34|92001.92|\n| 165|      Kirk|     Haddon|admin@azurelib.com|  Male| 46136|1975-07-12 23:15:40|68143.38|\n| 169|    Jamesy|      Gilby|admin@azurelib.com|  Male|153493|1971-01-28 04:00:18|27030.09|\n+----+----------+-----------+------------------+------+------+-------------------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "df2 = df.na.fill(\"admin@azurelib.com\", subset=[\"email\"])\n",
    "df2.where(\"email = 'admin@azurelib.com'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d39815e9-f12a-497e-a658-fc9f1c98d271",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "<b> Remove all the records where any record has any null values. Find out the total count of the records now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1035982-814b-43ff-b9df-55e89c658f68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n|preCleaningRowCount|\n+-------------------+\n|               1000|\n+-------------------+\n\n+--------------------+\n|postCleaningRowCount|\n+--------------------+\n|                 512|\n+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "current_row_count = df.select(count('*').alias('preCleaningRowCount'))\n",
    "current_row_count.show()\n",
    "df_remove_null = df.na.drop(\"any\")\n",
    "post_row_count = df_remove_null.select(count('id').alias('postCleaningRowCount'))\n",
    "post_row_count.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Databricks-Basic Data Cleaning Transformation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
